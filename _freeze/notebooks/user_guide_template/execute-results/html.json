{
  "hash": "24f52a6f6a93c88cf396545a55ad77d0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data User Guide Template\"\noutput: html_document\ndate: \"2026-01-15\"\nauthor: \"Camilla Green\"\n---\n# Data User Guide Template\n\n\n## Examples:\n- TOPST SCHOOL project: https://ciesin-geospatial.github.io/TOPSTSCHOOL-SPHINX/\n  - Specific lesson: NRT Water Lesson: https://ciesin-geospatial.github.io/TOPSTSCHOOL-water/m102-lance-modis-nrt-global-flood.html\n- Pytidycensus examples page: https://github.com/mmann1123/pytidycensus/tree/main/examples \n- NASA Earthdata Cloud Cookbook: https://nasa-openscapes.github.io/earthdata-cloud-cookbook/tutorials/\n- GSAPP Smorgasbord: https://cdp.arch.columbia.edu/smorgasbord/modules/5-computational-design-modeling-in-grasshopper/5-7_Design-Space/\n\n## Tips and Pointers\n- Provide links to any relevant URLs including code packages, data documentation\n- Provide links to other help/guides when relevant instead of DIY. For example, link to a guide on accessing REST APIs instead of writing a whole section yourself. Two options for this:\n    - https://zapier.com/blog/how-to-use-api/#what \n    - https://guides.dataverse.org/en/6.8/api/getting-started.html\n- Use open source tools whenever possible to facilitate user accessibility. Where an open tool is not available, explain why the tool is necessary and point to some possible alternatives\n\n--- \n\n## 1. Overview\n\n### 1.1 What Is This Dataset?\n- Brief, plain-language description of the dataset  \n- Links to our datahub, API  \n- Time period covered  \n- Geographic or population coverage  \n- License (e.g., CC BY 4.0)\n- Citation guidance\n- Any usage restrictions\n\n\n### 1.2 Who Is This Data AND Tutorial For?\n- Intended audience \n- Suggested skill level (beginner / intermediate / advanced)\n\n---\n\n## 2. Key Questions This Data Can Answer\nList 5–6 example questions users can explore, in addition to the key question that we will be exploring in this guide.\n\n- How has X changed over time?\n- Are there differences in X by region or demographic group?\n- Which areas experience the highest or lowest values?\n\nExplain why this data set is appropriate to use to assess the key question. \n\n---\n\n## 3. Data Access\n\n### 3.1 Where to Find the Data\n- Link(s) to download location (portal, GitHub, API, cloud storage)\n- File formats available (CSV, Excel, Parquet, API endpoint)\n\n### 3.2 How to Download\nStep-by-step instructions:\n1. Navigate to …\n2. Click …\n3. Select format …\n\n> Include screenshots if possible.\n\n\n---\n\n## 4. Dataset Structure\n\n### 4.1 Files Included\n| File Name | Description |\n|----------|-------------|\n| data.csv | Main cleaned dataset |\n| codebook.csv | Variable definitions |\n| metadata.json | Collection and methodology details |\n\n### 4.2 Unit of Analysis\nClearly state what **one row represents**:\n\n- One road  \n- One ward  \n- One health facility \n- Etc  \n\n---\n\n## 5. Variables & Definitions\n\n### 5.1 Key Variables\nHighlight the most important fields.\n\n| Variable | Description | Type | Example |\n|--------|-------------|------|---------|\n| county | County name | Categorical | Cook |\n| year | Calendar year | Integer | 2022 |\n| funding_usd | Total funding | Numeric | 125000 |\n\n### 5.2 Missing Data\n- How missing values are represented (e.g., `NA`, blank, `-999`)\n- Known gaps or limitations\n\n---\n\n## 6. Data Quality & Limitations\n\n\n- Known sources of bias\n- Data collection limitations\n- Changes in methodology over time\n- What the data **should not** be used for  \n\n\n---\n\n## 7. Getting Started: Quick Setup\n\n### 7.1 Tools You Can Use\n- R  (which packages?)\n- Python  (which packages?)\n- ArcGIS Pro / QGIS\n- Excel / Google Sheets\n- Local computing requirements (if any) - provide alternatives to local processing\n  - JupyterLab/CoLab\n\n  \n  \n\n### 7.2 Load the Data\n### 7.3 Clean / Filter Data\n- Subset to year or area of interest\n\n### 7.4 EDA\n- Calculate summary statistics\n\n---\n\n## 8. Analysis / Visualization\n\n## 9. Conclusion / Summary / Further Steps\n\n--- \n\n# TO DO \n- Adapt Matt W's colab notebook that uses the roads dataset -> converts to a network -> calculates travel time \n  - Need to work out fix to access ArcGIS WMS in python\n\n- Determine if we will use Astro or Quarto? -> Matt H. and Juan are doing some tests\n\n- Map out which user guides we will develop next\n  - Catchment areas from friction surface\n  - DRC Data layers\n  - Waterways\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}